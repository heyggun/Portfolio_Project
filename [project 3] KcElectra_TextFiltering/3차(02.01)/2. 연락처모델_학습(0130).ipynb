{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4f7b93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc9c5cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1aa1ef4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device for Train : cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device for Train : {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5250fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03209dd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.ipynb_checkpoints', '2. 연락처모델_학습(0130).ipynb', '연락처학습데이터(0201).csv']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('./')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf555a81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conts</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>자기소개도 좋은데, 대화를 하고싶어도 하기위해서 비용이 계속 드는 거 같아요!! \"...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01058341164 연락처입니다 김효수라 하구요 마음이 따뜻해 지고 싶어요</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>010 9839 5444.  카톡 아이디 ibrokhim1122.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>대전에서 근무하는 35살 초등교사입니다. 자가, 자차 보유 중이고 부모님 노후 준비...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>외모상관없이 착하고 착한분 원합니다  가까우신분 연락주세요 77774332</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54771</th>\n",
       "      <td>어머니 전업주부 기독교 온화한 성격에 49년소띠 대구여고 본은 김녕김씨</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54772</th>\n",
       "      <td>두분모님께서는돌아가셨고 식구가많아요 4낭5녀중5벉째입니다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54773</th>\n",
       "      <td>사무직을 일하고 ㅣㅆ습니다.윙0 1명은 경영 핟면ㅇ은 교사로 일하고 있어요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54774</th>\n",
       "      <td>1남2녕 어머랑  따로  살고있어  각자  타지 산산ㆍ</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54775</th>\n",
       "      <td>Null (기재 사항이 없습니다.) _ Empty 한글 30자 padding</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>54776 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   conts  label\n",
       "0      자기소개도 좋은데, 대화를 하고싶어도 하기위해서 비용이 계속 드는 거 같아요!! \"...      1\n",
       "1             01058341164 연락처입니다 김효수라 하구요 마음이 따뜻해 지고 싶어요      1\n",
       "2                   010 9839 5444.  카톡 아이디 ibrokhim1122.      1\n",
       "3      대전에서 근무하는 35살 초등교사입니다. 자가, 자차 보유 중이고 부모님 노후 준비...      1\n",
       "4              외모상관없이 착하고 착한분 원합니다  가까우신분 연락주세요 77774332      1\n",
       "...                                                  ...    ...\n",
       "54771            어머니 전업주부 기독교 온화한 성격에 49년소띠 대구여고 본은 김녕김씨      0\n",
       "54772                    두분모님께서는돌아가셨고 식구가많아요 4낭5녀중5벉째입니다      0\n",
       "54773         사무직을 일하고 ㅣㅆ습니다.윙0 1명은 경영 핟면ㅇ은 교사로 일하고 있어요.      0\n",
       "54774                     1남2녕 어머랑  따로  살고있어  각자  타지 산산ㆍ      0\n",
       "54775         Null (기재 사항이 없습니다.) _ Empty 한글 30자 padding      0\n",
       "\n",
       "[54776 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('./연락처학습데이터(0201).csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2e8ebb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.loc[~data['conts'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf114a3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    30519\n",
       "1    24257\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ceec9bf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54776, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6de2da8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "call_df = data.copy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a0a215fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "call_df = call_df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d536063c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "conts    0\n",
       "label    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "call_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2503ae8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "call_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9f28c07b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30475, 2) (24239, 2)\n"
     ]
    }
   ],
   "source": [
    "label_0 = call_df.loc[call_df['label']==0]\n",
    "label_1 = call_df.loc[call_df['label']==1]\n",
    "\n",
    "print(label_0.shape, label_1.shape)\n",
    "\n",
    "final_call_df = pd.concat([label_0, label_1]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b07f327a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43771, 2) (10943, 2)\n"
     ]
    }
   ],
   "source": [
    "# 학습 데이터 : 검증 데이터 8:2\n",
    "\n",
    "train_data = final_call_df.sample(frac=0.8, random_state=2022)[['conts','label']]\n",
    "test_data = final_call_df.drop(train_data.index)[['conts','label']]\n",
    "\n",
    "print(train_data.shape, test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "22089c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'beomi/KcELECTRA-base'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "25fa55a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding(num_tokens=128, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])\n",
      "['[CLS]', '혼자', '##여도', '좋지만', '삶을', '나눌', '누군가', '##가', '있다면', '좀', '더', '행복', '##에', '가까워', '##지지', '않을까', '##하는', '생각이', '드는', '요즘', '##이네요', '.', '곁', '##에', '있으', '##므로', '평온', '##하고', '삶이', '더', '채워진', '##다고', '느껴', '##지는', '분이', '##라면', '가능', '##할', '것', '같아요', '.', '친구', '##같은', '분이', '##길', '바라', '##며', '최대', '4', '##살', '연상', '##까지만', '연락', '##주세요', '.', '(', '인증', '##하신', '##분', '##만', ')', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "[2, 8895, 12527, 18739, 13294, 31127, 12253, 4050, 10422, 2884, 874, 9554, 4063, 29962, 8851, 12062, 7974, 8896, 14887, 8378, 9844, 18, 254, 4063, 14279, 12576, 36227, 7977, 16889, 874, 48394, 7982, 10763, 8177, 11274, 8666, 8529, 4139, 213, 11259, 18, 9136, 8044, 11274, 4411, 9612, 4330, 10750, 24, 4026, 28877, 21381, 12790, 8496, 18, 12, 11159, 9715, 4048, 4220, 13, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "# train dataset 토크나이징\n",
    "tokenized_train_sentence = tokenizer(\n",
    "    list(train_data['conts']),\n",
    "    max_length=128,\n",
    "    return_tensors='pt',  #pyotorch의 tensor 형태로 return\n",
    "    padding=True,        #제로패딩 설정\n",
    "    truncation=True,     # max_length 초과 토큰 truncate\n",
    "    add_special_tokens=True)  # spcial token 추가\n",
    "\n",
    "\n",
    "print(tokenized_train_sentence[0])\n",
    "print(tokenized_train_sentence[0].tokens)\n",
    "print(tokenized_train_sentence[0].ids)\n",
    "print(tokenized_train_sentence[0].attention_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "96789a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test dataset 토크나이징\n",
    "tokenized_test_sentence = tokenizer(\n",
    "    list(test_data['conts']),\n",
    "    max_length=128,\n",
    "    return_tensors='pt',\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    add_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e40d5735",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding(num_tokens=128, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])\n",
      "['[CLS]', '.', '3년', '##전', '중학교', '(', '교장', ')', '에서', '정년', '##퇴직', '##하였', '##습니다', '>', '>', '사범', '##대', '##와', '사범', '##대', '교육', '##대학', '##원', '(', '교육학', '##석', '##사', ')', '.', '몸', '건강', '##하며', '일상생활', '(', '텃밭', '##채', '##소', ')', '을', '시작', '##했습니다', '.', '고향', '##이', '서울', '##토', '##박이', '##입니다', '.', '14', '.', '5', '##×', '##4', '.', '2', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "[2, 18, 9719, 4062, 23770, 12, 28752, 13, 11708, 23447, 34399, 23012, 8054, 25001, 25001, 32139, 4032, 4331, 32139, 4032, 8690, 13204, 4195, 12, 41244, 4424, 4029, 13, 18, 1519, 9249, 8490, 19232, 12, 31984, 4375, 4194, 13, 2710, 8438, 11953, 18, 12143, 4012, 8190, 4289, 11674, 8080, 18, 11520, 18, 25, 27107, 4214, 18, 22, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_test_sentence[0])\n",
    "print(tokenized_test_sentence[0].tokens)\n",
    "print(tokenized_test_sentence[0].ids)\n",
    "print(tokenized_test_sentence[0].attention_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bc2492f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(torch.utils.data.Dataset) :\n",
    "    def __init__(self, encodings, labels) :\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "        \n",
    "    def __len__(self) :\n",
    "        return len(self.labels)    \n",
    "        \n",
    "    def __getitem__(self, idx) :\n",
    "        item = {key : torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6318d22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset 형성(텐서로 변환)\n",
    "train_label = train_data['label'].values\n",
    "test_label = test_data['label'].values\n",
    "\n",
    "train_dataset = CustomDataset(tokenized_train_sentence, train_label)\n",
    "test_dataset = CustomDataset(tokenized_test_sentence, test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a496e0bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at beomi/KcELECTRA-base were not used when initializing ElectraForSequenceClassification: ['discriminator_predictions.dense.weight', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense_prediction.bias']\n",
      "- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at beomi/KcELECTRA-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ElectraForSequenceClassification(\n",
       "  (electra): ElectraModel(\n",
       "    (embeddings): ElectraEmbeddings(\n",
       "      (word_embeddings): Embedding(50135, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): ElectraEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): ElectraClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # 사전학습 모델 로드\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bd8956b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # train option setting\n",
    "train_arguments = TrainingArguments(\n",
    "                     output_dir='./',\n",
    "                     num_train_epochs=5,\n",
    "                    per_device_train_batch_size=64,\n",
    "                    per_device_eval_batch_size=64,\n",
    "                    logging_dir='./logs',\n",
    "                    logging_steps=500,\n",
    "                    save_total_limit=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bad06e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score, precision_score, recall_score\n",
    "\n",
    "\n",
    "def compute_metrics(pred) :\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    \n",
    "    precision = precision_score(labels, preds) \n",
    "    recall = recall_score(labels, preds)\n",
    "    f1 = precision_recall_fscore_support(labels, preds, average='binary')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    \n",
    "    return {\n",
    "        'accuracy' : acc,\n",
    "        'f1' : f1,\n",
    "        'precision' : precision,\n",
    "        'recall' : recall\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "30a9fac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 43771\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 64\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3420\n",
      "  Number of trainable parameters = 124546562\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3420' max='3420' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3420/3420 16:13:03, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.068400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.026200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.018200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.010200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.006400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.005600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./checkpoint-500\n",
      "Configuration saved in ./checkpoint-500\\config.json\n",
      "Model weights saved in ./checkpoint-500\\pytorch_model.bin\n",
      "Saving model checkpoint to ./checkpoint-1000\n",
      "Configuration saved in ./checkpoint-1000\\config.json\n",
      "Model weights saved in ./checkpoint-1000\\pytorch_model.bin\n",
      "Saving model checkpoint to ./checkpoint-1500\n",
      "Configuration saved in ./checkpoint-1500\\config.json\n",
      "Model weights saved in ./checkpoint-1500\\pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint-500] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint-2000\n",
      "Configuration saved in ./checkpoint-2000\\config.json\n",
      "Model weights saved in ./checkpoint-2000\\pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint-1000] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint-2500\n",
      "Configuration saved in ./checkpoint-2500\\config.json\n",
      "Model weights saved in ./checkpoint-2500\\pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint-1500] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint-3000\n",
      "Configuration saved in ./checkpoint-3000\\config.json\n",
      "Model weights saved in ./checkpoint-3000\\pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint-2000] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 16h 13min 21s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3420, training_loss=0.02014127976713125, metrics={'train_runtime': 58401.4764, 'train_samples_per_second': 3.747, 'train_steps_per_second': 0.059, 'total_flos': 1.43957925052032e+16, 'train_loss': 0.02014127976713125, 'epoch': 5.0})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Train\n",
    "train = Trainer(\n",
    "                model=model,\n",
    "                args=train_arguments,\n",
    "                train_dataset=train_dataset,\n",
    "                eval_dataset=test_dataset,\n",
    "                compute_metrics=compute_metrics)\n",
    "\n",
    "train.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "175ebbb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 10943\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='171' max='171' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [171/171 17:19]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"(0.9929911358482787, 0.9942208462332301, 0.9936056105610561, None)\" of type <class 'tuple'> for key \"eval/f1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.03489580750465393,\n",
       " 'eval_accuracy': 0.9943342776203966,\n",
       " 'eval_f1': (0.9929911358482787, 0.9942208462332301, 0.9936056105610561, None),\n",
       " 'eval_precision': 0.9929911358482787,\n",
       " 'eval_recall': 0.9942208462332301,\n",
       " 'eval_runtime': 1045.706,\n",
       " 'eval_samples_per_second': 10.465,\n",
       " 'eval_steps_per_second': 0.164,\n",
       " 'epoch': 5.0}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.evaluate(eval_dataset=test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac62542",
   "metadata": {},
   "source": [
    "        {'eval_loss': 0.039978399872779846,\n",
    "         'eval_accuracy': 0.9935406477807511,\n",
    "         'eval_f1': (0.9929299230609274, 0.992517148202037, 0.9927234927234927, None),\n",
    "         'eval_precision': 0.9929299230609274,\n",
    "         'eval_recall': 0.992517148202037,\n",
    "         'eval_runtime': 1026.504,\n",
    "         'eval_samples_per_second': 10.557,\n",
    "         'eval_steps_per_second': 0.166,\n",
    "         'epoch': 5.0}"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "11786ca4",
   "metadata": {},
   "source": [
    "`최종`\n",
    "\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ee19dca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "today = str(datetime.today())[:10]\n",
    "path = f\"{today}_call_model.pt\"\n",
    "\n",
    "# save model \n",
    "torch.save(model, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6faf77bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "today = str(datetime.today())[:10]\n",
    "path = f\"{today}_call_model.pt\"\n",
    "\n",
    "# save model \n",
    "torch.save(model, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5481a46a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ElectraForSequenceClassification(\n",
       "  (electra): ElectraModel(\n",
       "    (embeddings): ElectraEmbeddings(\n",
       "      (word_embeddings): Embedding(50135, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): ElectraEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): ElectraClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load model\n",
    "mod = torch.load(f\"{today}_call_model.pt\")\n",
    "mod.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2f06271a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "class Preprocessing():\n",
    "\n",
    "    def __init__(self, sent):\n",
    "        self.sent = sent\n",
    "\n",
    "    def clean_sentence(self):\n",
    "        try:  # 무성의\n",
    "            self.sent = re.sub('[^\\w\\s]', ' ', self.sent).strip()\n",
    "            self.sent = re.sub('[.,?!ᆢ~]', ', ', self.sent)\n",
    "            self.sent = re.sub('[ㄱ-ㅎ|ㅏ-ㅣ]', 'ㅋ', self.sent)\n",
    "            self.sent = re.sub('니다', '니다. ', self.sent)\n",
    "            self.sent = re.sub('어요', '어요. ', self.sent)\n",
    "            self.sent = re.sub('\\n', ' ', self.sent).strip()\n",
    "\n",
    "        except:\n",
    "            print('clean_sentence method fail')\n",
    "            pass\n",
    "\n",
    "        return self.sent\n",
    "\n",
    "    def f_clean_sentence(self):\n",
    "        try:\n",
    "            self.sent = re.sub('[^\\w\\s]', ' ', self.sent).strip()\n",
    "            self.sent = re.sub('[.,?!ᆢ~]', ', ', self.sent)\n",
    "            self.sent = self.return_text(self.sent)\n",
    "\n",
    "        except:\n",
    "            print('f_clean_sentence method fail')\n",
    "            pass\n",
    "        return self.sent\n",
    "\n",
    "    def sub_num(self, sent):\n",
    "        hannum_list = ['일', '이', '삼', '사', '오', '육', '륙', '칠', '팔', '구', '십', '영']\n",
    "        sent = re.sub(r'[0-9]', ' ', sent)\n",
    "\n",
    "        for i in hannum_list:\n",
    "            sent = re.sub(rf'{i}', '  ', sent)\n",
    "        return sent\n",
    "\n",
    "    def return_target_list(self, pattern, sent):\n",
    "        word_list = []\n",
    "        for i in pattern.finditer(sent):\n",
    "            target_word = sent[i.start(): i.end()]\n",
    "            word_list.append(target_word)\n",
    "        return word_list\n",
    "\n",
    "    def return_text(self, sent):\n",
    "\n",
    "        nam = '[남]+'\n",
    "        nyeo = '[녀]+'\n",
    "        yeo = '[여]+'\n",
    "        son = '[아들]+'\n",
    "        ddal = '[딸]+'\n",
    "        num = '[\\s]*(\\d){1,2}[\\s]*'\n",
    "        han_num = '[일이삼사오육륙칠팔구십]+'\n",
    "\n",
    "        person_list = [nam, son, nyeo, yeo, ddal]\n",
    "        num_list = [num, han_num]\n",
    "\n",
    "        for person_pattern in person_list:\n",
    "            for num_pattern in num_list:\n",
    "                pattern_list = [person_pattern + num_pattern, num_pattern + person_pattern]\n",
    "                target_list = []\n",
    "\n",
    "                for pattern in pattern_list:\n",
    "                    add_pattern = re.compile(pattern)\n",
    "                    m = add_pattern.findall(sent)\n",
    "                    if m != []:\n",
    "                        target_words = self.return_target_list(add_pattern, sent)\n",
    "                        target_list += target_words\n",
    "                    else:\n",
    "                        pass\n",
    "\n",
    "                for i in target_list:\n",
    "                    sent = sent.replace(i, self.sub_num(i))\n",
    "        return sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "362596a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class predictModel():\n",
    "\n",
    "    def __init__(self, model_path):\n",
    "        # load model\n",
    "        self.model_path = model_path\n",
    "        self.model = torch.load(model_path)\n",
    "        # set device\n",
    "        self.device = torch.device('cpu')\n",
    "        # load tokenizer\n",
    "        model_name = 'beomi/KcELECTRA-base'\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "    def predict_sentence(self, sent):\n",
    "        self.model.eval()\n",
    "        Pr = Preprocessing(sent)\n",
    "\n",
    "        if 'call' in str(self.model_path):\n",
    "            sent = Pr.f_clean_sentence()\n",
    "\n",
    "        else:\n",
    "            sent = Pr.clean_sentence()\n",
    "\n",
    "        # tokenizing\n",
    "        tokenized_sent = self.tokenizer(\n",
    "            sent,\n",
    "            return_tensors='pt',\n",
    "            truncation=True,\n",
    "            add_special_tokens=True,\n",
    "            max_length=512\n",
    "        )\n",
    "        tokenized_sent.to(self.device)\n",
    "\n",
    "        # prediction\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(\n",
    "                input_ids=tokenized_sent['input_ids'],\n",
    "                attention_mask=tokenized_sent['attention_mask'],\n",
    "                token_type_ids=tokenized_sent['token_type_ids']\n",
    "            )\n",
    "\n",
    "        # result\n",
    "        per = int(str(np.array(F.softmax(outputs[0][0], dim=0).detach().cpu())[1] * 100).split('.')[0])\n",
    "\n",
    "        if len(sent) <= 5:\n",
    "            # 10자 이하는 연락처 로 탐지하지 않음\n",
    "            return 1, int(per)\n",
    "\n",
    "        result = outputs[0].detach().cpu().argmax(-1)\n",
    "\n",
    "        if int(result) == 0:\n",
    "            return int(result), int(per)\n",
    "\n",
    "        return int(result), int(per)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fb6771b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "today = str(datetime.today())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ed377b9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at C:\\Users\\PC/.cache\\huggingface\\hub\\models--beomi--KcELECTRA-base\\snapshots\\5b4ca19e087a144c05a307ef109b3295aeae4588\\config.json\n",
      "Model config ElectraConfig {\n",
      "  \"_name_or_path\": \"beomi/KcELECTRA-base\",\n",
      "  \"architectures\": [\n",
      "    \"ElectraForPreTraining\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"embedding_size\": 768,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"electra\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"summary_activation\": \"gelu\",\n",
      "  \"summary_last_dropout\": 0.1,\n",
      "  \"summary_type\": \"first\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"tokenizer_class\": \"BertTokenizer\",\n",
      "  \"transformers_version\": \"4.25.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50135\n",
      "}\n",
      "\n",
      "loading file vocab.txt from cache at C:\\Users\\PC/.cache\\huggingface\\hub\\models--beomi--KcELECTRA-base\\snapshots\\5b4ca19e087a144c05a307ef109b3295aeae4588\\vocab.txt\n",
      "loading file tokenizer.json from cache at None\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at C:\\Users\\PC/.cache\\huggingface\\hub\\models--beomi--KcELECTRA-base\\snapshots\\5b4ca19e087a144c05a307ef109b3295aeae4588\\special_tokens_map.json\n",
      "loading file tokenizer_config.json from cache at C:\\Users\\PC/.cache\\huggingface\\hub\\models--beomi--KcELECTRA-base\\snapshots\\5b4ca19e087a144c05a307ef109b3295aeae4588\\tokenizer_config.json\n",
      "loading configuration file config.json from cache at C:\\Users\\PC/.cache\\huggingface\\hub\\models--beomi--KcELECTRA-base\\snapshots\\5b4ca19e087a144c05a307ef109b3295aeae4588\\config.json\n",
      "Model config ElectraConfig {\n",
      "  \"_name_or_path\": \"beomi/KcELECTRA-base\",\n",
      "  \"architectures\": [\n",
      "    \"ElectraForPreTraining\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"embedding_size\": 768,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"electra\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"summary_activation\": \"gelu\",\n",
      "  \"summary_last_dropout\": 0.1,\n",
      "  \"summary_type\": \"first\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"tokenizer_class\": \"BertTokenizer\",\n",
      "  \"transformers_version\": \"4.25.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50135\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at C:\\Users\\PC/.cache\\huggingface\\hub\\models--beomi--KcELECTRA-base\\snapshots\\5b4ca19e087a144c05a307ef109b3295aeae4588\\config.json\n",
      "Model config ElectraConfig {\n",
      "  \"_name_or_path\": \"beomi/KcELECTRA-base\",\n",
      "  \"architectures\": [\n",
      "    \"ElectraForPreTraining\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"embedding_size\": 768,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"electra\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"summary_activation\": \"gelu\",\n",
      "  \"summary_last_dropout\": 0.1,\n",
      "  \"summary_type\": \"first\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"tokenizer_class\": \"BertTokenizer\",\n",
      "  \"transformers_version\": \"4.25.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50135\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "call_model = predictModel(model_path = f\"{today}_call_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397131a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8653f9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ac747f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
